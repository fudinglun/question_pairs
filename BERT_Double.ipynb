{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Double.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"e50cGF2LoxkC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"outputId":"298d36b6-49f2-487a-cb26-b4128d4b055b","executionInfo":{"status":"ok","timestamp":1555513287459,"user_tz":240,"elapsed":3088,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["!pip install pytorch_pretrained_bert\n","import pandas as pd\n","import numpy as np\n","import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import random\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","import pdb\n","import torch.optim as optim\n","import torch.nn.init as weigth_init\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":110,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.130)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.130)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (2.5.3)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (0.14)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (1.11.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"gkmneBk2o48z","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m2Rns4X0o7Q6","colab_type":"code","colab":{}},"cell_type":"code","source":["dir_path = \"drive/My Drive/quora\"\n","train_data = pd.read_csv(\"{}/data/train.csv\".format(dir_path))\n","valid_data = pd.read_csv(\"{}/data/valid.csv\".format(dir_path))\n","test_data = pd.read_csv(\"{}/data/test.csv\".format(dir_path))\n","train_data.dropna(inplace=True)\n","valid_data.dropna(inplace=True)\n","test_data.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wxp-V6Nao-eZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"911d8f91-4023-4db7-9704-8a43c224a19b","executionInfo":{"status":"ok","timestamp":1555510491477,"user_tz":240,"elapsed":254,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"0_FBo6N-pBFo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4998},"outputId":"19068c15-a24d-4467-b4a5-0b740563ccd3","executionInfo":{"status":"ok","timestamp":1555510509561,"user_tz":240,"elapsed":16271,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model.eval()\n","model.to(device)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"seGx0Q4-pDLB","colab_type":"code","colab":{}},"cell_type":"code","source":["class QDataSet(Dataset):\n","    def __init__(self, dataframe, tokenizer, seq_length=30):\n","        self.df = dataframe\n","        self.tokenizer = tokenizer\n","        self.seq_length = seq_length\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        q1 = row.question1\n","        q2 = row.question2\n","        \n","        exchange = random.choice([0, 1])\n","        if exchange == 1:\n","          q1, q2 = q2, q1\n","        \n","        label = int(row.is_duplicate)\n","        #form tokens\n","        q1 = [\"[CLS]\"] + tokenizer.tokenize(q1) + [\"[SEP]\"]\n","        q2 = [\"[CLS]\"] + tokenizer.tokenize(q2) + [\"[SEP]\"]\n","        #get token ids\n","        q1_ids = tokenizer.convert_tokens_to_ids(q1)\n","        q2_ids = tokenizer.convert_tokens_to_ids(q2)\n","        #cut sentence larger than max len\n","        q1_ids = q1_ids[:self.seq_length]\n","        q2_ids = q2_ids[:self.seq_length]\n","        #init mast\n","        q1_mask = [1]*len(q1_ids)\n","        q2_mask = [1]*len(q2_ids)\n","        \n","    \n","        #add padding\n","        while len(q1_ids) < self.seq_length:\n","            q1_ids.append(0)\n","            q1_mask.append(0)\n","            \n","        while len(q2_ids) < self.seq_length:\n","            q2_ids.append(0)\n","            q2_mask.append(0)\n","            \n","        \n","        return np.array(q1_ids), np.array(q1_mask), sum(q1_mask), np.array(q2_ids), np.array(q2_mask), sum(q2_mask), label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Amqu8RNmpFq4","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset = QDataSet(train_data, tokenizer)\n","valid_dataset = QDataSet(valid_data, tokenizer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JUb9leJJpHp4","colab_type":"code","colab":{}},"cell_type":"code","source":["def sort_batch(data, seq_len, device):\n","    sorted_seq_len, sorted_idx = torch.sort(seq_len, dim=0, descending=True)\n","    sorted_data = data[sorted_idx.data]\n","    _, reverse_idx = torch.sort(sorted_idx, dim=0, descending=False)\n","    return sorted_data, sorted_seq_len.to(device), reverse_idx.to(device)\n","  \n","def softmax_mask(input, mask, device, axis=1, epsilon=1e-12):\n","    shift, _ = torch.max(input, axis, keepdim=True)\n","    shift = shift.expand_as(input).to(device)\n","\n","    target_exp = torch.exp(input - shift) * mask\n","\n","    normalize = torch.sum(target_exp, axis, keepdim=True).expand_as(target_exp)\n","    softm = target_exp / (normalize + epsilon)\n","\n","    return softm.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IhqZVaUUpIyo","colab_type":"code","colab":{}},"cell_type":"code","source":["def valid(model, bert_model, criteria, valid_data, batch_size, shuffle, device):\n","    model.eval()\n","    bert_model.eval()\n","    seq_length = valid_data.seq_length\n","    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=shuffle)\n","    loss_arr = []\n","    for i_batch, sample_batch in enumerate(valid_loader):\n","        q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","\n","        output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","        loss = criteria(output, label)\n","        loss_arr.append(loss.item())\n","    return loss_arr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gO7nk8b4pK64","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_embedding(sample_batch, seq_length, device, bert_model):\n","  q1_ids, q1_mask, q1_len, q2_ids, q2_mask, q2_len, label = sample_batch\n","  input_type_ids = torch.zeros([q1_ids.shape[0], seq_length], dtype=torch.int64).to(device)\n","  \n","  q1_ids = torch.tensor(q1_ids).to(device)\n","  q2_ids = torch.tensor(q2_ids).to(device)\n","  label = torch.tensor(label).to(device)\n","  \n","  #sort the batch\n","  s_q1, s_q1_len, reverse_q1_idx = sort_batch(q1_ids, q1_len, device)\n","  s_q2, s_q2_len, reverse_q2_idx = sort_batch(q2_ids, q2_len, device)\n","  \n","  #get embedding\n","  with torch.no_grad():\n","      q1_vecs, _ = bert_model(s_q1, input_type_ids)\n","      q2_vecs, _ = bert_model(s_q2, input_type_ids)\n","  q1_vecs = pack(q1_vecs[-1], list(s_q1_len.data), batch_first=True)\n","  q2_vecs = pack(q2_vecs[-1], list(s_q2_len.data), batch_first=True)\n","  \n","  #get mask\n","  q1_mask = torch.tensor(q1_mask[:, :max(q1_len)]).to(device)\n","  q2_mask = torch.tensor(q2_mask[:, :max(q2_len)]).to(device)\n","  \n","  return q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y0H00IrdpMjH","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(model, optimizer, criteria, bert_model, train_data, valid_data, batch_size, shuffle, epoch, device, start_epoch):\n","    \n","    bert_model.eval()\n","    seq_length = train_data.seq_length\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n","    for e in range(start_epoch, start_epoch + epoch):\n","        model.train()\n","        for i_batch, sample_batch in enumerate(train_loader):\n","            q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","            #get in the model\n","            optimizer.zero_grad()\n","            output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","            loss = criteria(output, label)\n","            loss.backward()\n","            optimizer.step()\n","            if i_batch%50==0:\n","                print(i_batch, loss.item())\n","\n","\n","        print(\"Validating the model\")\n","        loss_arr = valid(model=model, bert_model=bert_model, criteria=criteria, valid_data=valid_data, batch_size=batch_size, shuffle=shuffle, device=device)\n","        print(\"Finish an epoch with validation loss {}, training loss {}\".format(np.mean(loss_arr), loss.item()))         \n","        torch.save(model.state_dict(), \"drive/My Drive/quora/trained_models/doubleatt/{0}_{1:.2f}_LSTMATT.pt\".format(e, np.mean(loss_arr)))\n","        print(\"Saved the model.\")\n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"9dDolAyxpOf3","colab_type":"code","colab":{}},"cell_type":"code","source":["class LSTMMaskFC(nn.Module):\n","    def __init__(self, device, input_size=768, hidden_size=100, fc_size=50):\n","        super(LSTMMaskFC, self).__init__()\n","        self.device = device\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n","        self.lstm2 = nn.LSTM(input_size=hidden_size*2, hidden_size=fc_size, batch_first=True)\n","        self.fc = nn.Linear(fc_size, 2)\n","        \n","        for weight in self.lstm.parameters():\n","          if len(weight.size()) > 1:\n","            weigth_init.orthogonal(weight.data)\n","        \n","        for weight in self.lstm2.parameters():\n","          if len(weight.size()) > 1:\n","            weigth_init.orthogonal(weight.data)\n","        \n","    def forward(self, q1, q2, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len):\n","        #encode\n","        o1, _ = self.lstm(q1)\n","        o2, _ = self.lstm(q2)\n","        \n","        #unpack\n","        o1, _ = unpack(o1, batch_first=True)\n","        o2, _ = unpack(o2, batch_first=True)\n","        \n","        o1 = o1[reverse_q1_idx.data]\n","        o2 = o2[reverse_q2_idx.data]\n","        \n","        #q1, q2 dot product\n","        q1_mask= q1_mask.unsqueeze(2)\n","        q2_mask = q2_mask.unsqueeze(2)\n","        \n","        M = torch.bmm(o1, o2.transpose(1, 2))\n","        M_mask = torch.bmm(q1_mask.float(), q2_mask.transpose(1, 2).float())\n","        \n","        #q1, q2 attention\n","        alpha = softmax_mask(M, M_mask, self.device, axis=1)\n","        beta = softmax_mask(M, M_mask, self.device, axis=2)\n","        \n","        out1 = torch.bmm(alpha.transpose(1, 2), o1)\n","        out2 = torch.bmm(beta, o2)\n","        out = torch.cat([out1, out2], dim=1)\n","        out, _ = self.lstm2(out)\n","        out = F.relu(self.fc(out[:, -1, :]))\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ajvki0ObpQA3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"09e88726-3fce-4d44-a11c-03a525886424","executionInfo":{"status":"ok","timestamp":1555513625014,"user_tz":240,"elapsed":335,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["clf = LSTMMaskFC(device)\n","clf.to(device)\n","criteria = nn.CrossEntropyLoss()"],"execution_count":137,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"}]},{"metadata":{"id":"Mx-Scu_MpSbP","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.Adam(clf.parameters(), lr=5e-3, weight_decay=1e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M_v9PxQopUav","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4825},"outputId":"1377f2d4-8f40-4d8f-b676-01daf2131a39","executionInfo":{"status":"error","timestamp":1555543615301,"user_tz":240,"elapsed":28523720,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["train(model=clf ,optimizer=optimizer, criteria= criteria, bert_model=model, train_data=dataset, valid_data=valid_dataset, \n","      batch_size=256, shuffle=True, epoch=20, device=device,start_epoch=0)"],"execution_count":139,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.6946611404418945\n","50 0.637941300868988\n","100 0.5767993927001953\n","150 0.5562760233879089\n","200 0.5939701795578003\n","250 0.5507162809371948\n","300 0.5615918040275574\n","350 0.5942558646202087\n","400 0.520839512348175\n","450 0.45356228947639465\n","500 0.5201494097709656\n","550 0.4521747827529907\n","600 0.47806647419929504\n","650 0.4455339312553406\n","700 0.4605766534805298\n","750 0.5221773982048035\n","800 0.5354828238487244\n","850 0.4668600559234619\n","900 0.4719173014163971\n","950 0.4564690887928009\n","1000 0.5270183682441711\n","1050 0.4880661368370056\n","1100 0.4708237051963806\n","Validating the model\n","Finish an epoch with validation loss 0.4726138611634572, training loss 0.4964253008365631\n","Saved the model.\n","0 0.47074970602989197\n","50 0.49443840980529785\n","100 0.4928201735019684\n","150 0.49719473719596863\n","200 0.48849254846572876\n","250 0.45496752858161926\n","300 0.4742561876773834\n","350 0.46424174308776855\n","400 0.48887109756469727\n","450 0.48542362451553345\n","500 0.4449363350868225\n","550 0.44195544719696045\n","600 0.5137490630149841\n","650 0.4909050762653351\n","700 0.500913679599762\n","750 0.47431448101997375\n","800 0.4268108904361725\n","850 0.42475008964538574\n","900 0.45515841245651245\n","950 0.4821041524410248\n","1000 0.5007393956184387\n","1050 0.4929468333721161\n","1100 0.45386284589767456\n","Validating the model\n","Finish an epoch with validation loss 0.4703860886489289, training loss 0.4198329746723175\n","Saved the model.\n","0 0.4689832627773285\n","50 0.45435068011283875\n","100 0.46539029479026794\n","150 0.4452521800994873\n","200 0.42878609895706177\n","250 0.4325602948665619\n","300 0.4201379716396332\n","350 0.47203007340431213\n","400 0.4955127239227295\n","450 0.40805065631866455\n","500 0.47155314683914185\n","550 0.4146322011947632\n","600 0.4363766312599182\n","650 0.4084846079349518\n","700 0.4714602530002594\n","750 0.45941194891929626\n","800 0.40003207325935364\n","850 0.5112825632095337\n","900 0.41539299488067627\n","950 0.48769450187683105\n","1000 0.4139505624771118\n","1050 0.4608294367790222\n","1100 0.43369513750076294\n","Validating the model\n","Finish an epoch with validation loss 0.4628759431436595, training loss 0.42092621326446533\n","Saved the model.\n","0 0.4386400282382965\n","50 0.4179127514362335\n","100 0.47918882966041565\n","150 0.4361141622066498\n","200 0.4348023533821106\n","250 0.49091872572898865\n","300 0.5157977342605591\n","350 0.4796089231967926\n","400 0.4970725476741791\n","450 0.4551289975643158\n","500 0.46252065896987915\n","550 0.484176367521286\n","600 0.4797353148460388\n","650 0.47720709443092346\n","700 0.4098324775695801\n","750 0.45103710889816284\n","800 0.45670995116233826\n","850 0.4701533913612366\n","900 0.44681236147880554\n","950 0.44542133808135986\n","1000 0.4247782826423645\n","1050 0.44280141592025757\n","1100 0.41600802540779114\n","Validating the model\n","Finish an epoch with validation loss 0.45787495638750775, training loss 0.4348679482936859\n","Saved the model.\n","0 0.4700348675251007\n","50 0.4433940351009369\n","100 0.4364892542362213\n","150 0.4491792321205139\n","200 0.4591832458972931\n","250 0.4334530830383301\n","300 0.4518512189388275\n","350 0.44271060824394226\n","400 0.4018617570400238\n","450 0.4750414192676544\n","500 0.46209222078323364\n","550 0.43115365505218506\n","600 0.5412963032722473\n","650 0.4250507354736328\n","700 0.40894725918769836\n","750 0.45330309867858887\n","800 0.45294997096061707\n","850 0.4631422162055969\n","900 0.46199122071266174\n","950 0.4691311717033386\n","1000 0.4162977933883667\n","1050 0.4030296504497528\n","1100 0.44685670733451843\n","Validating the model\n","Finish an epoch with validation loss 0.45668267348647623, training loss 0.43459081649780273\n","Saved the model.\n","0 0.447424054145813\n","50 0.47031325101852417\n","100 0.5085828900337219\n","150 0.40800848603248596\n","200 0.4615786671638489\n","250 0.43703359365463257\n","300 0.40761399269104004\n","350 0.45309025049209595\n","400 0.4291810691356659\n","450 0.479256272315979\n","500 0.47402387857437134\n","550 0.4327242076396942\n","600 0.43994227051734924\n","650 0.4762577712535858\n","700 0.4442618489265442\n","750 0.469131201505661\n","800 0.472252756357193\n","850 0.43549638986587524\n","900 0.3825860023498535\n","950 0.47307443618774414\n","1000 0.4387779235839844\n","1050 0.4725938141345978\n","1100 0.48647430539131165\n","Validating the model\n","Finish an epoch with validation loss 0.4588016358357442, training loss 0.4468120038509369\n","Saved the model.\n","0 0.4984486997127533\n","50 0.4477171003818512\n","100 0.44148170948028564\n","150 0.46370914578437805\n","200 0.383934885263443\n","250 0.4503238797187805\n","300 0.4187279939651489\n","350 0.45813506841659546\n","400 0.45888131856918335\n","450 0.510810136795044\n","500 0.5073897838592529\n","550 0.4930003583431244\n","600 0.5047714710235596\n","650 0.4376097023487091\n","700 0.4569469392299652\n","750 0.40415921807289124\n","800 0.4608079195022583\n","850 0.46591073274612427\n","900 0.44587448239326477\n","950 0.4882504343986511\n","1000 0.4543307423591614\n","1050 0.42236649990081787\n","1100 0.4187121093273163\n","Validating the model\n","Finish an epoch with validation loss 0.45597379381143593, training loss 0.4090330898761749\n","Saved the model.\n","0 0.4441009759902954\n","50 0.4974794387817383\n","100 0.45688092708587646\n","150 0.4325030446052551\n","200 0.4503507912158966\n","250 0.43761953711509705\n","300 0.4066937267780304\n","350 0.4303174614906311\n","400 0.4293864965438843\n","450 0.39912277460098267\n","500 0.45053255558013916\n","550 0.41405487060546875\n","600 0.477003276348114\n","650 0.4425826072692871\n","700 0.4730527698993683\n","750 0.46811002492904663\n","800 0.46799054741859436\n","850 0.4526843726634979\n","900 0.41453757882118225\n","950 0.4594802260398865\n","1000 0.4139579236507416\n","1050 0.4382645785808563\n","1100 0.45053407549858093\n","Validating the model\n","Finish an epoch with validation loss 0.4535273708371673, training loss 0.44269222021102905\n","Saved the model.\n","0 0.475314199924469\n","50 0.42716920375823975\n","100 0.47589340806007385\n","150 0.38967961072921753\n","200 0.4286661744117737\n","250 0.43748486042022705\n","300 0.44311007857322693\n","350 0.40291720628738403\n","400 0.5033906102180481\n","450 0.4673944413661957\n","500 0.44222086668014526\n","550 0.4382786452770233\n","600 0.46576127409935\n","650 0.4866279661655426\n","700 0.47254592180252075\n","750 0.4588095247745514\n","800 0.4724681079387665\n","850 0.4364655911922455\n","900 0.41459429264068604\n","950 0.4404240548610687\n","1000 0.4330246150493622\n","1050 0.4825458228588104\n","1100 0.4289276897907257\n","Validating the model\n","Finish an epoch with validation loss 0.4519467023103046, training loss 0.5306931138038635\n","Saved the model.\n","0 0.4368617832660675\n","50 0.44543713331222534\n","100 0.46858903765678406\n","150 0.43148839473724365\n","200 0.4811602532863617\n","250 0.47133293747901917\n","300 0.4231225848197937\n","350 0.39600950479507446\n","400 0.39665326476097107\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-139-8597eca8989f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(model=clf ,optimizer=optimizer, criteria= criteria, bert_model=model, train_data=dataset, valid_data=valid_dataset, \n\u001b[0;32m----> 2\u001b[0;31m       batch_size=256, shuffle=True, epoch=20, device=device,start_epoch=0)\n\u001b[0m","\u001b[0;32m<ipython-input-135-8b0d37459ddc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criteria, bert_model, train_data, valid_data, batch_size, shuffle, epoch, device, start_epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mq1_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_q1_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_q2_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m#get in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-134-1d7a03fd3bb8>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(sample_batch, seq_length, device, bert_model)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mq1_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mq2_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_q2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mq1_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_q1_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mq2_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq2_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_q2_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first)\u001b[0m\n\u001b[1;32m    145\u001b[0m                       \u001b[0;34m'the trace incorrect for any other combination of lengths.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                       category=torch.jit.TracerWarning, stacklevel=2)\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"4mrrrzczwdQp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}