{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_GRU.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"e50cGF2LoxkC","colab_type":"code","outputId":"0daefc10-3ca3-4a21-d16a-a9170cb872fc","executionInfo":{"status":"ok","timestamp":1555677451658,"user_tz":240,"elapsed":3301,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"cell_type":"code","source":["!pip install pytorch_pretrained_bert\n","import pandas as pd\n","import numpy as np\n","import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import random\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","import pdb\n","import torch.optim as optim\n","import torch.nn.init as weigth_init\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.130)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.130)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (0.14)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (2.5.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (1.11.0)\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"gkmneBk2o48z","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m2Rns4X0o7Q6","colab_type":"code","colab":{}},"cell_type":"code","source":["dir_path = \"drive/My Drive/quora\"\n","train_data = pd.read_csv(\"{}/data/train.csv\".format(dir_path))\n","valid_data = pd.read_csv(\"{}/data/valid.csv\".format(dir_path))\n","test_data = pd.read_csv(\"{}/data/test.csv\".format(dir_path))\n","train_data.dropna(inplace=True)\n","valid_data.dropna(inplace=True)\n","test_data.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wxp-V6Nao-eZ","colab_type":"code","outputId":"a504415c-1623-443e-8c96-5b5289869e9f","executionInfo":{"status":"ok","timestamp":1555677456303,"user_tz":240,"elapsed":188,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"0_FBo6N-pBFo","colab_type":"code","outputId":"3a1764bf-a49d-4561-a776-b59dffa109ab","executionInfo":{"status":"ok","timestamp":1555677468587,"user_tz":240,"elapsed":10889,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}},"colab":{"base_uri":"https://localhost:8080/","height":4998}},"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model.eval()\n","model.to(device)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"seGx0Q4-pDLB","colab_type":"code","colab":{}},"cell_type":"code","source":["class QDataSet(Dataset):\n","    def __init__(self, dataframe, tokenizer, seq_length=30):\n","        self.df = dataframe\n","        self.tokenizer = tokenizer\n","        self.seq_length = seq_length\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        q1 = row.question1\n","        q2 = row.question2\n","        \n","        exchange = random.choice([0, 1])\n","        if exchange == 1:\n","          q1, q2 = q2, q1\n","        \n","        label = int(row.is_duplicate)\n","        #form tokens\n","        q1 = [\"[CLS]\"] + tokenizer.tokenize(q1) + [\"[SEP]\"]\n","        q2 = [\"[CLS]\"] + tokenizer.tokenize(q2) + [\"[SEP]\"]\n","        #get token ids\n","        q1_ids = tokenizer.convert_tokens_to_ids(q1)\n","        q2_ids = tokenizer.convert_tokens_to_ids(q2)\n","        #cut sentence larger than max len\n","        q1_ids = q1_ids[:self.seq_length]\n","        q2_ids = q2_ids[:self.seq_length]\n","        #init mast\n","        q1_mask = [1]*len(q1_ids)\n","        q2_mask = [1]*len(q2_ids)\n","        \n","    \n","        #add padding\n","        while len(q1_ids) < self.seq_length:\n","            q1_ids.append(0)\n","            q1_mask.append(0)\n","            \n","        while len(q2_ids) < self.seq_length:\n","            q2_ids.append(0)\n","            q2_mask.append(0)\n","            \n","        \n","        return np.array(q1_ids), np.array(q1_mask), sum(q1_mask), np.array(q2_ids), np.array(q2_mask), sum(q2_mask), label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Amqu8RNmpFq4","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset = QDataSet(train_data, tokenizer)\n","valid_dataset = QDataSet(valid_data, tokenizer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JUb9leJJpHp4","colab_type":"code","colab":{}},"cell_type":"code","source":["def sort_batch(data, seq_len, device):\n","    sorted_seq_len, sorted_idx = torch.sort(seq_len, dim=0, descending=True)\n","    sorted_data = data[sorted_idx.data]\n","    _, reverse_idx = torch.sort(sorted_idx, dim=0, descending=False)\n","    return sorted_data, sorted_seq_len.to(device), reverse_idx.to(device)\n","  \n","def softmax_mask(input, mask, device, axis=1, epsilon=1e-12):\n","    shift, _ = torch.max(input, axis, keepdim=True)\n","    shift = shift.expand_as(input).to(device)\n","\n","    target_exp = torch.exp(input - shift) * mask\n","\n","    normalize = torch.sum(target_exp, axis, keepdim=True).expand_as(target_exp)\n","    softm = target_exp / (normalize + epsilon)\n","\n","    return softm.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IhqZVaUUpIyo","colab_type":"code","colab":{}},"cell_type":"code","source":["def valid(model, bert_model, criteria, valid_data, batch_size, shuffle, device):\n","    model.eval()\n","    bert_model.eval()\n","    seq_length = valid_data.seq_length\n","    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=shuffle)\n","    loss_arr = []\n","    for i_batch, sample_batch in enumerate(valid_loader):\n","        q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","\n","        output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","        loss = criteria(output, label)\n","        loss_arr.append(loss.item())\n","    return loss_arr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gO7nk8b4pK64","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_embedding(sample_batch, seq_length, device, bert_model):\n","  q1_ids, q1_mask, q1_len, q2_ids, q2_mask, q2_len, label = sample_batch\n","  input_type_ids = torch.zeros([q1_ids.shape[0], seq_length], dtype=torch.int64).to(device)\n","  \n","  q1_ids = torch.tensor(q1_ids).to(device)\n","  q2_ids = torch.tensor(q2_ids).to(device)\n","  label = torch.tensor(label).to(device)\n","  \n","  #sort the batch\n","  s_q1, s_q1_len, reverse_q1_idx = sort_batch(q1_ids, q1_len, device)\n","  s_q2, s_q2_len, reverse_q2_idx = sort_batch(q2_ids, q2_len, device)\n","  \n","  #get embedding\n","  with torch.no_grad():\n","      q1_vecs, _ = bert_model(s_q1, input_type_ids)\n","      q2_vecs, _ = bert_model(s_q2, input_type_ids)\n","  q1_vecs = pack(q1_vecs[-1], list(s_q1_len.data), batch_first=True)\n","  q2_vecs = pack(q2_vecs[-1], list(s_q2_len.data), batch_first=True)\n","  \n","  #get mask\n","  q1_mask = torch.tensor(q1_mask[:, :max(q1_len)]).to(device)\n","  q2_mask = torch.tensor(q2_mask[:, :max(q2_len)]).to(device)\n","  \n","  return q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y0H00IrdpMjH","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(model, optimizer, criteria, bert_model, train_data, valid_data, batch_size, shuffle, epoch, device, start_epoch):\n","    \n","    bert_model.eval()\n","    seq_length = train_data.seq_length\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n","    for e in range(start_epoch, start_epoch + epoch):\n","        model.train()\n","        for i_batch, sample_batch in enumerate(train_loader):\n","            q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","            #get in the model\n","            optimizer.zero_grad()\n","            output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","            loss = criteria(output, label)\n","            loss.backward()\n","            optimizer.step()\n","            if i_batch%50==0:\n","                print(i_batch, loss.item())\n","\n","\n","        print(\"Validating the model\")\n","        loss_arr = valid(model=model, bert_model=bert_model, criteria=criteria, valid_data=valid_data, batch_size=batch_size, shuffle=shuffle, device=device)\n","        print(\"Finish an epoch with validation loss {}, training loss {}\".format(np.mean(loss_arr), loss.item()))         \n","        torch.save(model.state_dict(), \"drive/My Drive/quora/trained_models/gru/{0}_{1:.2f}_LSTMATT.pt\".format(e, np.mean(loss_arr)))\n","        print(\"Saved the model.\")\n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"9dDolAyxpOf3","colab_type":"code","colab":{}},"cell_type":"code","source":["class GRUFC(nn.Module):\n","    def __init__(self, device, input_size=768, hidden_size=100, fc_size=50):\n","        super(GRUFC, self).__init__()\n","        self.device = device\n","        self.gru = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n","        self.bilinear = nn.Bilinear(hidden_size*2, hidden_size*2, fc_size)\n","        self.fc = nn.Linear(hidden_size*2 + fc_size, fc_size)\n","        self.fc2 = nn.Linear(fc_size, 2)\n","        self.hidden_size = hidden_size\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","        self.relu3 = nn.ReLU()\n","        \n","        for weight in self.gru.parameters():\n","          if len(weight.size()) > 1:\n","            weigth_init.orthogonal(weight.data)\n","        \n","        \n","        \n","    def forward(self, q1, q2, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len):\n","        #encode and get the last hidden state\n","        _, h1 = self.gru(q1)\n","        _, h2 = self.gru(q2)\n","        \n","        \n","        #stack the hidden\n","        h1 = h1[0].view((-1, self.hidden_size*2))\n","        h2 = h2[0].view((-1, self.hidden_size*2))\n","        \n","        #unpack the order\n","        h1 = h1[reverse_q1_idx.data]\n","        h2 = h2[reverse_q2_idx.data]\n","        \n","        bi_out = self.relu1(self.bilinear(h1, h2))\n","        \n","        diff = torch.abs(h1 - h2)\n","        \n","        out = torch.cat([bi_out, diff], dim=1)\n","        \n","        out = self.relu3(self.fc2(self.relu2(self.fc(out))))\n","        \n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ajvki0ObpQA3","colab_type":"code","outputId":"cd73f5cd-6698-41a8-e354-15233ab2ff4a","executionInfo":{"status":"ok","timestamp":1555680777405,"user_tz":240,"elapsed":400,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["clf = GRUFC(device)\n","clf.to(device)\n","criteria = nn.CrossEntropyLoss()"],"execution_count":108,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"metadata":{"id":"Mx-Scu_MpSbP","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.Adam(clf.parameters(), lr=1e-3, weight_decay=1e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M_v9PxQopUav","colab_type":"code","colab":{}},"cell_type":"code","source":["train(model=clf ,optimizer=optimizer, criteria= criteria, bert_model=model, train_data=dataset, valid_data=valid_dataset, \n","      batch_size=256, shuffle=True, epoch=20, device=device,start_epoch=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4mrrrzczwdQp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}