{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_ATTLSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"SuUU5x1842hI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"a5249bd4-637d-4656-83eb-a2fcdeed0b43","executionInfo":{"status":"ok","timestamp":1555514520248,"user_tz":240,"elapsed":6405,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["!pip install pytorch_pretrained_bert\n","import pandas as pd\n","import numpy as np\n","import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import random\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","import pdb\n","import torch.optim as optim\n","import torch.nn.init as weigth_init\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.130)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.130)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (0.14)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (2.5.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch_pretrained_bert) (1.11.0)\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"Ua42ipd648rV","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e3lMGPrT5Eya","colab_type":"code","colab":{}},"cell_type":"code","source":["dir_path = \"drive/My Drive/quora\"\n","train_data = pd.read_csv(\"{}/data/train.csv\".format(dir_path))\n","valid_data = pd.read_csv(\"{}/data/valid.csv\".format(dir_path))\n","test_data = pd.read_csv(\"{}/data/test.csv\".format(dir_path))\n","train_data.dropna(inplace=True)\n","valid_data.dropna(inplace=True)\n","test_data.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GguGRqAP5GDK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"758b9676-9c39-4e74-a8ba-11926cc1b500","executionInfo":{"status":"ok","timestamp":1555514553864,"user_tz":240,"elapsed":184,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"DDjcigb15HTz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4998},"outputId":"e2eea0ed-6f3a-4e16-c47d-244d24a84660","executionInfo":{"status":"ok","timestamp":1555514587762,"user_tz":240,"elapsed":28289,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model.eval()\n","model.to(device)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"__5bfVNr5Iua","colab_type":"code","colab":{}},"cell_type":"code","source":["class QDataSet(Dataset):\n","    def __init__(self, dataframe, tokenizer, seq_length=30):\n","        self.df = dataframe\n","        self.tokenizer = tokenizer\n","        self.seq_length = seq_length\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        q1 = row.question1\n","        q2 = row.question2\n","        \n","        exchange = random.choice([0, 1])\n","        if exchange == 1:\n","          q1, q2 = q2, q1\n","        \n","        label = int(row.is_duplicate)\n","        #form tokens\n","        q1 = [\"[CLS]\"] + tokenizer.tokenize(q1) + [\"[SEP]\"]\n","        q2 = [\"[CLS]\"] + tokenizer.tokenize(q2) + [\"[SEP]\"]\n","        #get token ids\n","        q1_ids = tokenizer.convert_tokens_to_ids(q1)\n","        q2_ids = tokenizer.convert_tokens_to_ids(q2)\n","        #cut sentence larger than max len\n","        q1_ids = q1_ids[:self.seq_length]\n","        q2_ids = q2_ids[:self.seq_length]\n","        #init mast\n","        q1_mask = [1]*len(q1_ids)\n","        q2_mask = [1]*len(q2_ids)\n","        \n","    \n","        #add padding\n","        while len(q1_ids) < self.seq_length:\n","            q1_ids.append(0)\n","            q1_mask.append(0)\n","            \n","        while len(q2_ids) < self.seq_length:\n","            q2_ids.append(0)\n","            q2_mask.append(0)\n","            \n","        \n","        return np.array(q1_ids), np.array(q1_mask), sum(q1_mask), np.array(q2_ids), np.array(q2_mask), sum(q2_mask), label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zj-Olpgu5K-x","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset = QDataSet(train_data, tokenizer)\n","valid_dataset = QDataSet(valid_data, tokenizer)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r9cf8lBP5MkR","colab_type":"code","colab":{}},"cell_type":"code","source":["def sort_batch(data, seq_len, device):\n","    sorted_seq_len, sorted_idx = torch.sort(seq_len, dim=0, descending=True)\n","    sorted_data = data[sorted_idx.data]\n","    _, reverse_idx = torch.sort(sorted_idx, dim=0, descending=False)\n","    return sorted_data, sorted_seq_len.to(device), reverse_idx.to(device)\n","  \n","def softmax_mask(input, mask, device, axis=1, epsilon=1e-12):\n","    shift, _ = torch.max(input, axis, keepdim=True)\n","    shift = shift.expand_as(input).to(device)\n","\n","    target_exp = torch.exp(input - shift) * mask\n","\n","    normalize = torch.sum(target_exp, axis, keepdim=True).expand_as(target_exp)\n","    softm = target_exp / (normalize + epsilon)\n","\n","    return softm.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e44p9yZJ5N1J","colab_type":"code","colab":{}},"cell_type":"code","source":["def valid(model, bert_model, criteria, valid_data, batch_size, shuffle, device):\n","    model.eval()\n","    bert_model.eval()\n","    seq_length = valid_data.seq_length\n","    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=shuffle)\n","    loss_arr = []\n","    for i_batch, sample_batch in enumerate(valid_loader):\n","        q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","\n","        output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","        loss = criteria(output, label)\n","        loss_arr.append(loss.item())\n","    return loss_arr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hyAPy7kg5PEC","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_embedding(sample_batch, seq_length, device, bert_model):\n","  q1_ids, q1_mask, q1_len, q2_ids, q2_mask, q2_len, label = sample_batch\n","  input_type_ids = torch.zeros([q1_ids.shape[0], seq_length], dtype=torch.int64).to(device)\n","  \n","  q1_ids = torch.tensor(q1_ids).to(device)\n","  q2_ids = torch.tensor(q2_ids).to(device)\n","  label = torch.tensor(label).to(device)\n","  \n","  #sort the batch\n","  s_q1, s_q1_len, reverse_q1_idx = sort_batch(q1_ids, q1_len, device)\n","  s_q2, s_q2_len, reverse_q2_idx = sort_batch(q2_ids, q2_len, device)\n","  \n","  #get embedding\n","  with torch.no_grad():\n","      q1_vecs, _ = bert_model(s_q1, input_type_ids)\n","      q2_vecs, _ = bert_model(s_q2, input_type_ids)\n","  q1_vecs = pack(q1_vecs[-1], list(s_q1_len.data), batch_first=True)\n","  q2_vecs = pack(q2_vecs[-1], list(s_q2_len.data), batch_first=True)\n","  \n","  #get mask\n","  q1_mask = torch.tensor(q1_mask[:, :max(q1_len)]).to(device)\n","  q2_mask = torch.tensor(q2_mask[:, :max(q2_len)]).to(device)\n","  \n","  return q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"raZFthco5QdB","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(model, optimizer, criteria, bert_model, train_data, valid_data, batch_size, shuffle, epoch, device, start_epoch):\n","    \n","    bert_model.eval()\n","    seq_length = train_data.seq_length\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n","    for e in range(start_epoch, start_epoch + epoch):\n","        model.train()\n","        for i_batch, sample_batch in enumerate(train_loader):\n","            q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len, label = get_embedding(sample_batch, seq_length, device, bert_model)\n","            #get in the model\n","            optimizer.zero_grad()\n","            output = model(q1_vecs, q2_vecs, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len.to(device), q2_len.to(device))\n","            loss = criteria(output, label)\n","            loss.backward()\n","            optimizer.step()\n","            if i_batch%50==0:\n","                print(i_batch, loss.item())\n","#             break\n","#         continue\n","\n","        print(\"Validating the model\")\n","        loss_arr = valid(model=model, bert_model=bert_model, criteria=criteria, valid_data=valid_data, batch_size=batch_size, shuffle=shuffle, device=device)\n","        print(\"Finish an epoch with validation loss {}, training loss {}\".format(np.mean(loss_arr), loss.item()))         \n","        torch.save(model.state_dict(), \"drive/My Drive/quora/trained_models/att_lstm/{0}_{1:.2f}_LSTMATT.pt\".format(e, np.mean(loss_arr)))\n","        print(\"Saved the model.\")\n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"QTvz3cF45Rzx","colab_type":"code","colab":{}},"cell_type":"code","source":["class LSTMMaskFC(nn.Module):\n","    def __init__(self, device, input_size=768, hidden_size=100, fc_size=50):\n","        super(LSTMMaskFC, self).__init__()\n","        self.device = device\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n","        self.fc1 = nn.Linear(hidden_size*4, fc_size)\n","        self.fc2 = nn.Linear(fc_size, 2)\n","        \n","        for weight in self.lstm.parameters():\n","          if len(weight.size()) > 1:\n","            weigth_init.orthogonal(weight.data)\n","\n","        \n","    def forward(self, q1, q2, reverse_q1_idx, reverse_q2_idx, q1_mask, q2_mask, q1_len, q2_len):\n","\n","        \n","        #unpack\n","        o1, _ = unpack(q1, batch_first=True)\n","        o2, _ = unpack(q2, batch_first=True)\n","        \n","        o1 = o1[reverse_q1_idx.data]\n","        o2 = o2[reverse_q2_idx.data]\n","        \n","        #q1, q2 dot product\n","        q1_mask= q1_mask.unsqueeze(2)\n","        q2_mask = q2_mask.unsqueeze(2)\n","        \n","        M = torch.bmm(o1, o2.transpose(1, 2))\n","        M_mask = torch.bmm(q1_mask.float(), q2_mask.transpose(1, 2).float())\n","        \n","        #q1, q2 attention\n","        alpha = softmax_mask(M, M_mask, self.device, axis=1)\n","        beta = softmax_mask(M, M_mask, self.device, axis=2)\n","        \n","        out1 = torch.bmm(alpha.transpose(1, 2), o1)\n","        out2 = torch.bmm(beta, o2)\n","        out1, _ = self.lstm(out1)\n","        out2, _ = self.lstm(out2)\n","        \n","        out = torch.cat([out1[:, -1, :], out2[:, -1, :]], dim=1)\n","        out = F.relu(self.fc1(out))\n","        \n","        out = F.relu(self.fc2(out))\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Bs8sEzy6DkJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"8310b75c-5cdd-4195-b7e8-4d93bd0ac6e8","executionInfo":{"status":"ok","timestamp":1555515014718,"user_tz":240,"elapsed":470,"user":{"displayName":"Dylan Fu","photoUrl":"","userId":"12662073190220995861"}}},"cell_type":"code","source":["clf = LSTMMaskFC(device)\n","clf.to(device)\n","criteria = nn.CrossEntropyLoss()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"}]},{"metadata":{"id":"bMYgJUCr6I75","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.Adam(clf.parameters(), lr=5e-3, weight_decay=1e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KgWCTgGC6KbZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3131},"outputId":"f409edb1-f94b-4de0-b2b5-9bd83a92469a"},"cell_type":"code","source":["train(model=clf ,optimizer=optimizer, criteria= criteria, bert_model=model, train_data=dataset, valid_data=valid_dataset, \n","      batch_size=256, shuffle=True, epoch=20, device=device,start_epoch=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.6931474804878235\n","50 0.6320931911468506\n","100 0.5813612341880798\n","150 0.5238048434257507\n","200 0.5572337508201599\n","250 0.5908418893814087\n","300 0.4915110766887665\n","350 0.5673909783363342\n","400 0.5592517852783203\n","450 0.5189058780670166\n","500 0.524715781211853\n","550 0.5247702598571777\n","600 0.451886385679245\n","650 0.5230859518051147\n","700 0.5193924307823181\n","750 0.5465618371963501\n","800 0.468985378742218\n","850 0.5537930727005005\n","900 0.5406456589698792\n","950 0.47395995259284973\n","1000 0.5079203844070435\n","1050 0.49402469396591187\n","1100 0.495651513338089\n","Validating the model\n","Finish an epoch with validation loss 0.5000382314754438, training loss 0.39936140179634094\n","Saved the model.\n","0 0.5125454664230347\n","50 0.5472338795661926\n","100 0.47860488295555115\n","150 0.5035973191261292\n","200 0.49229592084884644\n","250 0.4867461919784546\n","300 0.45573514699935913\n","350 0.5074822902679443\n","400 0.5281082987785339\n","450 0.45395585894584656\n","500 0.5155036449432373\n","550 0.4880293011665344\n","600 0.49315473437309265\n","650 0.4870426058769226\n","700 0.544783890247345\n","750 0.5051620602607727\n","800 0.5034191012382507\n","850 0.4661198556423187\n","900 0.48534151911735535\n","950 0.5037631392478943\n","1000 0.48806583881378174\n","1050 0.4929390251636505\n","1100 0.4809754192829132\n","Validating the model\n","Finish an epoch with validation loss 0.48540288398537457, training loss 0.5075723528862\n","Saved the model.\n","0 0.47357526421546936\n","50 0.4856266677379608\n","100 0.5163952708244324\n","150 0.4275253415107727\n","200 0.5128101110458374\n","250 0.5024852752685547\n","300 0.49875950813293457\n","350 0.47798895835876465\n","400 0.4366380274295807\n","450 0.5705015063285828\n","500 0.5019537806510925\n","550 0.4637060761451721\n","600 0.48471903800964355\n","650 0.44573938846588135\n","700 0.4653216004371643\n","750 0.48235541582107544\n","800 0.46180427074432373\n","850 0.4864709675312042\n","900 0.3983978033065796\n","950 0.4955540895462036\n","1000 0.501896858215332\n","1050 0.4559549391269684\n","1100 0.49957865476608276\n","Validating the model\n","Finish an epoch with validation loss 0.4819985370344251, training loss 0.4430585503578186\n","Saved the model.\n","0 0.4503074586391449\n","50 0.45547446608543396\n","100 0.4295717775821686\n","150 0.4540881812572479\n","200 0.462546169757843\n","250 0.5017098784446716\n","300 0.5137962698936462\n","350 0.4727376103401184\n","400 0.4601474404335022\n","450 0.494030237197876\n","500 0.4272242486476898\n","550 0.4661161005496979\n","600 0.4540688395500183\n","650 0.4539942741394043\n","700 0.4473039209842682\n","750 0.442471444606781\n","800 0.4805043935775757\n","850 0.4997578561306\n","900 0.4916556179523468\n","950 0.5297295451164246\n","1000 0.47560200095176697\n","1050 0.48668861389160156\n","1100 0.477933406829834\n","Validating the model\n","Finish an epoch with validation loss 0.4769089995305749, training loss 0.391793817281723\n","Saved the model.\n","0 0.49211350083351135\n","50 0.4828492999076843\n","100 0.4493192434310913\n","150 0.4262542128562927\n","200 0.45530587434768677\n","250 0.49896201491355896\n","300 0.4857725501060486\n","350 0.4360489249229431\n","400 0.45350363850593567\n","450 0.4825316369533539\n","500 0.48092037439346313\n","550 0.468863308429718\n","600 0.47177812457084656\n","650 0.4749775826931\n","700 0.4914471507072449\n","750 0.49525654315948486\n","800 0.4700363874435425\n","850 0.4389383792877197\n","900 0.46580740809440613\n","950 0.44347912073135376\n","1000 0.5316309928894043\n","1050 0.47124341130256653\n","1100 0.49149560928344727\n","Validating the model\n","Finish an epoch with validation loss 0.47882032520157375, training loss 0.508510947227478\n","Saved the model.\n","0 0.4571162760257721\n","50 0.437425822019577\n","100 0.4544678330421448\n","150 0.49508732557296753\n","200 0.48070797324180603\n","250 0.5261600017547607\n","300 0.45491281151771545\n","350 0.4854620099067688\n","400 0.47948479652404785\n","450 0.45489516854286194\n","500 0.4511898458003998\n","550 0.3923446834087372\n","600 0.4191857874393463\n","650 0.45122474431991577\n","700 0.5551209449768066\n","750 0.4621509611606598\n","800 0.47197356820106506\n","850 0.46229875087738037\n","900 0.49121010303497314\n","950 0.47716784477233887\n","1000 0.5240207314491272\n","1050 0.4929991662502289\n","1100 0.5445288419723511\n","Validating the model\n","Finish an epoch with validation loss 0.477764403392494, training loss 0.4339861273765564\n","Saved the model.\n","0 0.445666640996933\n","50 0.4716062843799591\n","100 0.4527934193611145\n","150 0.4326152801513672\n","200 0.4380131959915161\n","250 0.46979525685310364\n","300 0.47460252046585083\n","350 0.4485192894935608\n","400 0.48176833987236023\n","450 0.4249689280986786\n","500 0.4538627564907074\n","550 0.4957297444343567\n","600 0.4860527217388153\n","650 0.4726901054382324\n","700 0.47531411051750183\n","750 0.4740389585494995\n","800 0.46240222454071045\n","850 0.4987695813179016\n"],"name":"stdout"}]},{"metadata":{"id":"1a9rxxz76Qnh","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}