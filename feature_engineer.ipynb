{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from fuzzywuzzy import fuzz\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from rouge import Rouge\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wmd_model = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "# wmd_norm_model = norm_model = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "# wmd_norm_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train_quora_features.csv\")\n",
    "valid_data = pd.read_csv(\"../data/valid_quora_features.csv\")\n",
    "test_data = pd.read_csv(\"../data/test_quora_features.csv\")\n",
    "train_data.dropna(inplace=True)\n",
    "valid_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_lower_question(q):\n",
    "    q = [x.lower() for x in word_tokenize(q) if x.isalpha()]\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bleu(q1, q2):\n",
    "    #counting the matching n-gram of two questios\n",
    "    q1 = tokenize_lower_question(q1)\n",
    "    q2 = tokenize_lower_question(q2)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([q1], q2, smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rouge_1(q1, q2):\n",
    "    scores = rouge.get_scores(q1, q2)\n",
    "    return scores[0][\"rouge-1\"]['f']\n",
    "\n",
    "def get_rouge_2(q1, q2):\n",
    "    scores = rouge.get_scores(q1, q2)\n",
    "    return scores[0][\"rouge-2\"]['f']\n",
    "\n",
    "def get_rouge_l(q1, q2):\n",
    "    scores = rouge.get_scores(q1, q2)\n",
    "    return scores[0][\"rouge-l\"]['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_levenshteinDistance(s1, s2):\n",
    "    \"\"\"Edit distance\"\"\"\n",
    "    s1 = tokenize_lower_question(s1)\n",
    "    s2 = tokenize_lower_question(s2)\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_of_capital(q1):\n",
    "    num_capital = sum([1 for x in q1 if x.isupper()])\n",
    "    \n",
    "    return num_capital\n",
    "\n",
    "def get_num_of_question_mark(q1):\n",
    "    num_question_mark = sum([1 for x in q1 if x == '?' ])\n",
    "    return num_question_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):    \n",
    "    \n",
    "    #edit distance\n",
    "#     df[\"edit_distance\"] = df.apply(lambda x: get_levenshteinDistance(x.question1, x.question2), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rouge\n",
    "    df[\"rouge_1\"] = df.apply(lambda x: get_rouge_1(x.question1, x.question2), axis=1)\n",
    "    df[\"rouge_2\"] = df.apply(lambda x: get_rouge_2(x.question1, x.question2), axis=1)\n",
    "    df[\"rouge_l\"] = df.apply(lambda x: get_rouge_l(x.question1, x.question2), axis=1)\n",
    "    \n",
    "    #get special\n",
    "    df[\"q1_capital\"] = df.apply(lambda x: get_num_of_capital(x.question1), axis=1)\n",
    "    df[\"q2_capital\"] = df.apply(lambda x: get_num_of_capital(x.question2), axis=1)\n",
    "    df[\"capital_diff\"] = (df[\"q1_capital\"] - df[\"q2_capital\"]).abs()\n",
    "    \n",
    "    df[\"q1_question_mark\"] = df.apply(lambda x: get_num_of_question_mark(x.question1), axis=1)\n",
    "    df[\"q2_question_mark\"] = df.apply(lambda x: get_num_of_question_mark(x.question2), axis=1)\n",
    "    df[\"question_mark_diff\"] = (df[\"q1_question_mark\"] - df[\"q2_question_mark\"]).abs()\n",
    "\n",
    "\n",
    "#bleu\n",
    "    #     df[\"bleu\"] = df.apply(lambda x: get_bleu(x.question1, x.question2), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_engineer(train_data)\n",
    "# train_data.to_csv('../data/train_quora_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = feature_engineer(valid_data)\n",
    "# valid_data.to_csv('../data/valid_quora_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data[\"is_duplicate\"]\n",
    "X_train = train_data.drop([\"Unnamed: 0\", \"id\",\"qid1\",\"qid2\",\"question1\",\"question2\",\"is_duplicate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid = valid_data[\"is_duplicate\"]\n",
    "X_valid = valid_data.drop([\"Unnamed: 0\", \"id\",\"qid1\",\"qid2\",\"question1\",\"question2\",\"is_duplicate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "# from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.replace(np.inf, 7, inplace=True)\n",
    "X_valid.replace(np.inf, 7, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param = {'num_leaves':31, 'num_trees':100, 'objective':'binary'}\n",
    "# param['metric'] = ['binary_logloss']\n",
    "# num_round = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "# lgb_valid = lgb.Dataset(X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "gb = GradientBoostingClassifier()\n",
    "sgd = SGDClassifier(penalty=\"elasticnet\", loss='log')\n",
    "clf = VotingClassifier(estimators=[('rf', rf), ('gb', gb), ('sgd',sgd)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we...cnet', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49190131835102485"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(data):\n",
    "    graph = {}\n",
    "    for i in range(data.shape[0]):\n",
    "        sample = data.iloc[i]\n",
    "        \n",
    "        q1_id, q2_id, label = sample.qid1, sample.qid2, sample.is_duplicate\n",
    "        if int(label) == 0:\n",
    "            continue\n",
    "        if q1_id not in graph:\n",
    "            graph[q1_id] = []\n",
    "        graph[q1_id].append(q2_id)\n",
    "        \n",
    "        if q2_id not in graph:\n",
    "            graph[q2_id] = []\n",
    "        graph[q2_id].append(q1_id)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_graph.pickle\",'rb') as f:\n",
    "    train_graph = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_neighbor(graph, q1_id, q2_id):\n",
    "    seen = set()\n",
    "    queue = [q1_id]\n",
    "    while len(queue) > 0:\n",
    "        cur = queue.pop(0)\n",
    "        seen.add(cur)\n",
    "        if q2_id == cur:\n",
    "            return 1\n",
    "        else:\n",
    "            if cur not in graph:\n",
    "                return 0\n",
    "            for new in graph[cur]:\n",
    "                if new not in seen:\n",
    "                    queue.append(new)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_predict(graph, test_data, predict):\n",
    "    modified = np.copy(predict)\n",
    "    for i in range(test_data.shape[0]):\n",
    "        sample = test_data.iloc[i]\n",
    "        q1_id, q2_id = sample.qid1, sample.qid2\n",
    "        if is_neighbor(graph, q1_id, q2_id) == 1:\n",
    "            modified[i][0] = 0\n",
    "            modified[i][1] = 1\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_pred = modify_predict(train_graph, valid_data, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30264549627254494"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid, modified_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "3point6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
